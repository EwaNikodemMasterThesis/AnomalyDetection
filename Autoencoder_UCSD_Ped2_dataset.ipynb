{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XcYJWl4SWkkr","outputId":"d241e4fc-1446-4c3b-a970-2ab333e5289d","scrolled":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'UCSD'...\n","remote: Enumerating objects: 53469, done.\u001b[K\n","remote: Counting objects: 100% (4/4), done.\u001b[K\n","remote: Compressing objects: 100% (4/4), done.\u001b[K\n","remote: Total 53469 (delta 0), reused 4 (delta 0), pack-reused 53465\u001b[K\n","Receiving objects: 100% (53469/53469), 1.90 GiB | 27.77 MiB/s, done.\n","Resolving deltas: 100% (2686/2686), done.\n","Checking out files: 100% (54648/54648), done.\n"]}],"source":["!git clone https://github.com/EwaNikodemMasterThesis/AnomalyDetection.git"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWSJpsyKqHjH","outputId":"7fea5dd7-4a70-4197-937c-8eb02f1492a5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GETEftO1HI0z","outputId":"84f7f58c-05e6-4727-e933-e511c24da52b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 5.4 MB/s \n","\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n","Installing collected packages: tensorflow-addons\n","Successfully installed tensorflow-addons-0.15.0\n"]}],"source":["!pip install tensorflow-addons"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IQMRiVtTRspX"},"outputs":[],"source":["#ground truth\n","TestVideoFile = {}\n","TestVideoFile[1] = range(60,180)\n","TestVideoFile[2] = range(94,180)\n","TestVideoFile[3] = range(0,146)\n","TestVideoFile[4] = range(30,180)\n","TestVideoFile[5] = range(0,129)\n","TestVideoFile[6] = range(0,159)\n","TestVideoFile[7] = range(45,180)\n","TestVideoFile[8] = range(0,180)\n","TestVideoFile[9] = range(0,120)\n","TestVideoFile[10] = range(0,150)\n","TestVideoFile[11] = range(0,180)\n","TestVideoFile[12] = range(87,180)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJG6mnWEh0rC"},"outputs":[],"source":["import os\n","from os import listdir\n","from os.path import isfile, join, isdir\n","\n","\n","from PIL import Image\n","import numpy as np\n","import shelve\n","import keras\n","import tensorflow as tf \n","import tensorflow_addons as tfa\n","from keras.layers import Conv2DTranspose, ConvLSTM2D, BatchNormalization, TimeDistributed, Conv2D, LayerNormalization, MaxPooling2D, UpSampling2D\n","from tensorflow_addons.layers import MaxUnpooling2D\n","from keras.models import Sequential, load_model\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn import metrics\n","\n","\n","import shutil\n","import pathlib\n","\n","#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mXBoGhaXbUME"},"outputs":[],"source":["#the paths need to be changed accordingly \n","class Config:\n","  DATASET_PATH =\"/content/UCSD/UCSD_Anomaly_Dataset.v1p2/UCSDped2/Train\"\n","  DATASET_PATH_ALLIMAGES =\"/content/UCSD/UCSD_Anomaly_Dataset.v1p2/UCSDped2/All_images\"\n","  TEST_PATH =\"/content/UCSD/UCSD_Anomaly_Dataset.v1p2/UCSDped2/Test\"\n","  SINGLE_TEST_VIDEO_FILE = 3\n","  SINGLE_TEST_PATH = \"/content/UCSD/UCSD_Anomaly_Dataset.v1p2/UCSDped2/Test/Test003\"\n","  BATCH_SIZE = 32\n","  EPOCHS =  50  \n","  MODEL_PATH = \"/content/drive/MyDrive/UCSD/ped2_model_v1.hdf5\"\n","  MODEL_PATH_GEN = \"/content/drive/MyDrive/UCSD/ped2_model_gen_v1.hdf5\"\n","  TRAINING_SET_PATH = \"/content/drive/MyDrive/UCSD/ped2_trainingset_v1.npy\"\n","  THRESHOLD = 0.95"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhk1v0JSZNRM"},"outputs":[],"source":["#Copying all frames into 1 catalog to later feed it to generator\n","\n","pathlib.Path(Config.DATASET_PATH_ALLIMAGES).mkdir(parents=True, exist_ok=True)\n","\n","for subdir, dirs, files in os.walk(Config.DATASET_PATH):\n","  for f in files:\n","    if pathlib.Path(f).suffix == \".tif\":\n","      shutil.copy(join(Config.DATASET_PATH,subdir,f), join(Config.DATASET_PATH_ALLIMAGES, os.path.basename(subdir).lower()+\"_\"+f.lower()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wicE646MbgEy"},"outputs":[],"source":["def get_clips_by_stride(stride, frames_list, sequence_size):\n","#pre-processing, reshaping, putting into volumes\n","    clips = []\n","    sz = len(frames_list)\n","    clip = np.zeros(shape=(sequence_size, 224, 224, 1))\n","    cnt = 0\n","    for start in range(0, stride):\n","        for i in range(start, sz, stride):\n","            clip[cnt, :, :, 0] = frames_list[i]\n","            cnt = cnt + 1\n","            if cnt == sequence_size:\n","                clips.append(np.copy(clip))\n","                cnt = 0\n","    return clips\n","\n","\n","def get_training_set(reload_training_set=True):\n","\n","    if not reload_training_set:\n","        return np.load(Config.TRAINING_SET_PATH)\n","    \n","    clips = []\n","    \n","    for f in sorted(listdir(Config.DATASET_PATH)):\n","        if isdir(join(Config.DATASET_PATH, f)):\n","            all_frames = []\n","            \n","            for c in sorted(listdir(join(Config.DATASET_PATH, f))):\n","                if str(join(join(Config.DATASET_PATH, f), c))[-3:] == \"tif\":\n","                    img = Image.open(join(join(Config.DATASET_PATH, f), c)).convert('L').resize((224, 224))\n","                    \n","                    img = np.array(img, dtype=np.float32)\n","                    \n","                    img=(img-img.mean())/(img.std())\n","                    \n","                    img=np.clip(img,0,1)\n","                    all_frames.append(img)\n","            \n","            for stride in range(1, 3):\n","                clips.extend(get_clips_by_stride(stride=stride, frames_list=all_frames, sequence_size=10))\n","                \n","    \n","    np.save(Config.TRAINING_SET_PATH, clips)\n","    return clips\n","    \n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRHXG0CJh0rH"},"outputs":[],"source":["class DataGenerator(tf.keras.utils.Sequence):\n","\n","    def __init__(self, frame_list, batch_size):\n","        self.frame_list = frame_list\n","        self.batch_size = batch_size\n","\n","    def __len__(self):\n","      return (np.ceil(len(self.frame_list) / float(self.batch_size))).astype(np.int)\n","\n","    def __getitem__(self, index):\n","      frame_list_temp = self.frame_list[index * self.batch_size : (index+1) * self.batch_size]\n","\n","      # Set of X_train and y_train\n","      X, Y = self.__data_generation(frame_list_temp)\n","\n","      return X, Y\n","\n","    def __data_generation(self, frame_list_temp):\n","        frames = []\n","        for f in frame_list_temp:\n","          img = Image.open(join(Config.DATASET_PATH_ALLIMAGES, f)).convert('L').resize((224, 224))\n","\n","          img = np.array(img, dtype=np.float32)\n","          \n","          img=(img-img.mean())/(img.std())\n","\n","          \n","          img=np.clip(img,0,1)\n","          frames.append(img)\n","        \n","\n","        augmentation = []\n","        \n","        for stride in range(1, 3):\n","            augmentation.extend(get_clips_by_stride(stride=stride, frames_list=frames, sequence_size=10))\n","                \n","        training_set = np.array(augmentation)\n","        training_set = training_set.reshape(-1,10,224,224,1)\n","        \n","        return training_set, training_set.copy()\n","        \n","             \n","\n","\n","def get_model_gen(reload_model=True):\n","    if not reload_model:\n","        return load_model(Config.MODEL_PATH_GEN,custom_objects={'LayerNormalization': LayerNormalization})\n","    \n","    \n","    frames = []\n","    # loop over the all images\n","    for f in sorted(listdir(Config.DATASET_PATH_ALLIMAGES)):\n","      frames.append(f)\n","            \n","\n","    training_generator = DataGenerator(frames,Config.BATCH_SIZE)\n","\n","    model = Sequential()\n","    \n","    \n","\n","    #### Encoder ####\n","    model.add(TimeDistributed(Conv2D(512, (11, 11), strides=4, padding=\"valid\"), batch_input_shape=(None, 10, 224, 224, 1)))  #512\n","    model.add(LayerNormalization())\n","    model.add(TimeDistributed(MaxPooling2D((2, 2), padding=\"valid\")))#, strides = 1)))\n","\n","    model.add(TimeDistributed(Conv2D(256, (5, 5), strides= 1, padding=\"same\"))) #256\n","    model.add(LayerNormalization())  \n","    model.add(TimeDistributed(MaxPooling2D((2, 2), padding=\"valid\")))\n","\n","    model.add(TimeDistributed(Conv2D(128, (3, 3), padding=\"same\")))  #128\n","    \n","\n","    #### Decoder ####\n","\n","    model.add(TimeDistributed(Conv2DTranspose(128, (3, 3), padding=\"same\")))  #128\n","    model.add(LayerNormalization())\n","    \n","    model.add(TimeDistributed(UpSampling2D((2,2))))\n","    \n","\n","    model.add(TimeDistributed(Conv2DTranspose(256, (3, 3), padding=\"valid\")))  #256\n","    model.add(LayerNormalization())\n","    model.add(TimeDistributed(UpSampling2D((2,2))))\n","\n","    model.add(TimeDistributed(Conv2DTranspose(512, (5, 5), padding=\"same\")))  #512\n","    model.add(LayerNormalization())\n","    model.add(TimeDistributed(Conv2DTranspose(1, (11, 11), strides= 4, padding=\"same\")))\n","    \n","    \n","    print(model.summary())\n","\n","    model.compile(loss='mse', optimizer=tf.keras.optimizers.Adam(lr=1e-3)) #, decay=1e-5, epsilon=1e-6))\n","    \n","    \n","    model.fit_generator(generator=training_generator,\n","      epochs = Config.EPOCHS,\n","      verbose = 1,\n","      max_queue_size=Config.BATCH_SIZE,\n","      )\n","      \n","\n","    \n","    model.save(Config.MODEL_PATH_GEN)\n","    return model\n","    \n","get_model_gen()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PtjjZx6ObpKk"},"outputs":[],"source":["def get_single_test():\n","    sz = 0\n","\n","    for subdir, dirs, files in os.walk(Config.SINGLE_TEST_PATH):\n","      for f in files:\n","        if pathlib.Path(f).suffix == \".tif\":\n","          sz = sz + 1\n","\n","    test = np.zeros(shape=(sz, 224, 224, 1))\n","\n","    cnt = 0\n","    for f in sorted(listdir(Config.SINGLE_TEST_PATH)):\n","        if str(join(Config.SINGLE_TEST_PATH, f))[-3:] == \"tif\":\n","            img = Image.open(join(Config.SINGLE_TEST_PATH, f)).convert('L').resize((224, 224))\n","            img = np.array(img, dtype=np.float32)\n","            \n","            img=(img-img.mean())/(img.std())\n","            \n","            img=np.clip(img,0,1)\n","            test[cnt, :, :, 0] = img\n","            cnt = cnt + 1\n","    return test\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2NeQPTPsbsjT","scrolled":true},"outputs":[],"source":["def evaluate(reload_model=False):\n","    model = get_model_gen(reload_model)\n","    print(\"got model\")\n","    test = get_single_test()\n","    print(test.shape)\n","    sz = test.shape[0] - 10 + 1\n","    sequences = np.zeros((sz, 10, 224, 224, 1))\n","    \n","    for i in range(0, sz):\n","        clip = np.zeros((10, 224, 224, 1))\n","        for j in range(0, 10):\n","            clip[j] = test[i + j, :, :, :]\n","        sequences[i] = clip\n","\n","    print(\"got data\")\n","    # reconstruction error; regularity score\n","    reconstructed_sequences = model.predict(sequences,batch_size=Config.BATCH_SIZE)\n","    sequences_reconstruction_cost = np.array([np.linalg.norm(np.subtract(sequences[i],reconstructed_sequences[i])) for i in range(0,sz)])\n","    sa = (sequences_reconstruction_cost - np.min(sequences_reconstruction_cost)) / np.max(sequences_reconstruction_cost)\n","    sr = 1.0 - sa\n","\n","    # plot the regularity scores\n","    plt.plot(sr)\n","    plt.ylabel('regularity score Sr(t)')\n","    plt.xlabel('frame t')\n","    plt.show()\n","\n","    return sr, sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GvJfD_Hebwpp","scrolled":true},"outputs":[],"source":["pr, before_reconstuction = evaluate(reload_model=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qhbh8nTGd4Eo"},"outputs":[],"source":["def plotROC(pr):\n","  y_pred = pr\n","\n","  sz = 0\n","  for subdir, dirs, files in os.walk(Config.SINGLE_TEST_PATH):\n","    for f in files:\n","      if pathlib.Path(f).suffix == \".tif\":\n","        sz = sz + 1\n","\n","  y_test = [1 for element in range(0, sz)]\n","\n","  for i in TestVideoFile[Config.SINGLE_TEST_VIDEO_FILE]:\n","    y_test[i] = 0\n","\n","  \n","  y_test = y_test[5:sz-4]\n","\n","  if 1 not in y_test: \n","    y_test[0] = 1\n","\n","  fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n","  fnr = 1 - tpr\n","  auc = metrics.roc_auc_score(y_test, y_pred)\n","\n","  eer_threshold = thresholds[np.nanargmin(np.absolute((fnr - fpr)))]\n","  eer = fpr[np.nanargmin(np.absolute((fnr - fpr)))]\n","\n","  optimal = np.argmax(tpr - fpr)\n","  optimal_threshold = thresholds[optimal]\n","\n","  truePositive, falsePositive, falseNegative, trueNegative = 0,0,0,0 \n","      \n","  for ii in range(len(pr)):\n","      if pr[ii]<optimal_threshold and ii in TestVideoFile[Config.SINGLE_TEST_VIDEO_FILE]:\n","          truePositive +=1\n","      if pr[ii]<optimal_threshold and ii not in TestVideoFile[Config.SINGLE_TEST_VIDEO_FILE]:\n","          falsePositive += 1  \n","      if pr[ii]>optimal_threshold and ii in TestVideoFile[Config.SINGLE_TEST_VIDEO_FILE]:\n","          falseNegative +=1\n","      if pr[ii]>optimal_threshold and ii not in TestVideoFile[Config.SINGLE_TEST_VIDEO_FILE]:\n","          trueNegative += 1 \n","\n","\n","  #print(\"FPR: \", fpr)\n","  #print(\"TPR: \", tpr)\n","  #print(\"THRESHOLDS\", thresholds)\n","  print(\"AUC: \", auc)\n","  print(\"EER: \", eer)\n","  print(\"EER THRESHOLD: \", eer_threshold)\n","  print(\"Optimal threshold value is:\", optimal_threshold)\n","\n","  print(\"TP:\", truePositive, \" FP:\", falsePositive, \" FN:\", falseNegative, \"TN: \", trueNegative)\n","\n","  plt.title('Receiver Operating Characteristic')\n","  plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % auc)\n","  plt.legend(loc = 'lower right')\n","  plt.plot([0, 1], [0, 1],'r--')  \n","  plt.ylabel('True Positive Rate')\n","  plt.xlabel('False Positive Rate')\n","  plt.show()\n","\n","  plt.plot(y_test)\n","  plt.title('Ground Truth')\n","  plt.ylabel('GT')\n","  plt.xlabel('Frame')\n","  plt.show()\n","\n","  return auc, eer\n","\n","plotROC(pr)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DseWxOg7gxVf"},"outputs":[],"source":["clips = []\n","\n","for f in sorted(listdir(Config.TEST_PATH)):\n","    if isdir(join(Config.TEST_PATH, f)):\n","      if not 'gt' in f:\n","        clips.append(join(Config.TEST_PATH, f))\n","\n","\n","scores = []\n","\n","for i in range(len(clips)):\n","\n","\n","  Config.SINGLE_TEST_PATH = clips[i]\n","  Config.SINGLE_TEST_VIDEO_FILE = i+1\n","\n","  print(\"PATH: \", Config.SINGLE_TEST_PATH)\n","  print(\"GT: \", Config.SINGLE_TEST_VIDEO_FILE)\n","\n","  pr, before_reconstuction = evaluate()\n","  scores.append(plotROC(pr))\n","\n","\n","mean = np.mean(scores, axis=0)\n","#print(scores)\n","print(\"AUC: \", mean[0])\n","print(\"EER: \", mean[1])"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Autoencoder_UCSD_Ped2_dataset.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}